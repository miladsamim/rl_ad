Environment: CarRacing1670778727.3346174
seed: None
actions: {0: [-1, 0, 0], 1: [1, 0, 0], 2: [0, 1, 0], 3: [0, 0, 0.8], 4: [0, 0, 0]}
Architecture: DriveDQN_simple_fusion_lstm(
  (sensor_net): SensorModel(
    (cnn): Nature_Paper_Conv_Dropout_Torch(
      (layer1_cnn): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2))
      (layer2_cnn): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (layer3_cnn): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (layer_4_dense): Linear(in_features=9216, out_features=512, bias=True)
      (out_layer): Linear(in_features=512, out_features=128, bias=True)
    )
    (steering): Linear(in_features=1, out_features=128, bias=True)
    (speed): Linear(in_features=1, out_features=128, bias=True)
    (gyro): Linear(in_features=1, out_features=128, bias=True)
    (abs1): Linear(in_features=1, out_features=128, bias=True)
    (abs2): Linear(in_features=1, out_features=128, bias=True)
    (abs3): Linear(in_features=1, out_features=128, bias=True)
    (abs4): Linear(in_features=1, out_features=128, bias=True)
  )
  (action_emb): Embedding(5, 128)
  (cnn_1d_sensor): Conv1d(8, 8, kernel_size=(8,), stride=(4,), groups=8)
  (rnn): GRU(376, 128)
  (out): Linear(in_features=128, out_features=5, bias=True)
)
Explore Rate: max(0.1, (1 - float(training_metadata.frame) / training_metadata.frame_limit))
Learning Rate: 0.00025
Discount: 0.99
Batch Size: 32
Memory Capacity: 15000
Num Episodes: 3000
Learning Rate Drop Frame Limit: 250000
